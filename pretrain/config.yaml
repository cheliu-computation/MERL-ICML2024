network:
  # ecg_model: resnet18
  ecg_model: vit_tiny
  num_leads: 12
  ### this part does not control builder/trainer
  text_model: ncbi/MedCPT-Query-Encoder
  free_layers: 6 # set 12 to freeze all layer in bert
  feature_dim: 768

  projection_head:
    mlp_hidden_size: 256
    projection_size: 256
  ###

dataset:
  dataset_name: 'mimic'
  data_path: 'your_path/' # add your image file path here

# params for trainer
trainer:
  batch_size: 128
  val_batch_size: 512
  checkpoint_interval: 50
  max_epochs: 20
  num_workers: 8

optimizer:
  params:
    lr: 1.0e-3
    weight_decay: 1.0e-8

# params for zeroshot eval
zeroshot:
  prompt_type: 'CKEPE'
  prompt_dict: 'your_path/MERL/zeroshot/CKEPE_prompt.json'
  batch_size: 256
  num_workers: 8
  meta_data_path: 'your_path/downstream'
  meta_split_path: 'your_path/MERL/finetune/data_split'
  
  val_sets:
  ###
    ptbxl_super_class:
      data_path: 'ptbxl'
      split_path: 'ptbxl/super_class/ptbxl_super_class_val.csv'
  ###
    ptbxl_sub_class:
      data_path: 'ptbxl'
      split_path: 'ptbxl/sub_class/ptbxl_sub_class_val.csv'
  ###
    ptbxl_form:
      data_path: 'ptbxl'
      split_path: 'ptbxl/form/ptbxl_form_val.csv'
  ###
    ptbxl_rhythm:
      data_path: 'ptbxl'
      split_path: 'ptbxl/rhythm/ptbxl_rhythm_val.csv'
  ###
    icbeb:
      data_path: 'icbeb2018/records500'
      split_path: 'icbeb/icbeb_val.csv'
  ###
    chapman:
      data_path: ''
      split_path: 'chapman/chapman_val.csv'

# your model name
wandb_name: 'vit_tiny_demo'